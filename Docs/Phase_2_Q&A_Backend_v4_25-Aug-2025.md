# Phase 2 Q&A Backend - v4 (25-Aug-2025)

## Detailed Implementation Questions

### Q1: If freebies change from 2 â†’ 15, do *existing anonymous users* automatically get 15, or only new ones?
Existing anonymous users would automatically get 15 freebies. The current implementation uses cookies to track anonymous usage with the `anon_queries` cookie. When a request comes in, the system reads the current count from this cookie:

```javascript
function parseAnonCookie(req: NextRequest): { count: number } {
  try {
    const cookie = req.cookies.get('anon_queries');
    if (cookie?.value) {
      const parsed = JSON.parse(cookie.value);
      return { count: Number(parsed.count) || 0 };
    }
  } catch {}
  return { count: 0 };
}
```

It then compares this count to the hardcoded limit (currently 2):
```javascript
if (anonCount >= 2) {
  return corsify(
    req,
    NextResponse.json(
      {
        error: 'Free query limit reached. Create an account for more searches.',
        code: 'PAYMENT_REQUIRED',
        remaining: 0,
        isSubscriber: false,
        upgradeRequired: true,
      },
      { status: 402 }
    )
  );
}
```

Since the check happens at request time against the hardcoded limit, changing the limit from 2 to 15 would immediately allow existing anonymous users with cookies showing 2+ queries to continue making requests until they reach the new limit of 15.

### Q2: On OPTIONS preflight requests, what headers/methods are explicitly returned for `/api/ask-stream`?
For OPTIONS preflight requests to `/api/ask-stream`, the following headers are explicitly returned:

```javascript
{
  'Access-Control-Allow-Origin': origin, // Dynamically set based on request origin
  'Vary': 'Origin',
  'Access-Control-Allow-Headers': 'Content-Type, Authorization',
  'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
  'Access-Control-Max-Age': '86400'
}
```

The allowed methods are explicitly set to "GET, POST, OPTIONS", and the Access-Control-Max-Age header is set to 86400 seconds (24 hours) to reduce the number of preflight requests by enabling browsers to cache the preflight response.

### Q3: If a streaming request is aborted midway by the client, are credits consumed or rolled back?
Credits are consumed and not rolled back if a streaming request is aborted midway by the client. The code in `/api/v1/ria/search` and the behavior in other routes suggests that credits are decremented at the beginning of request processing, before the streaming begins:

```javascript
// Log this query (decrement credit)
await supabaseAdmin.from('user_queries').insert([{ user_id: userId }]);

// Then perform the actual operation...
```

There is no evidence of transaction handling or cleanup logic to roll back credit decrements if clients disconnect prematurely. Once the credit is decremented by inserting into the `user_queries` table, it remains decremented regardless of whether the client receives the complete response.

### Q4: Do backend logs differentiate between GET vs POST when 405 occurs, so we can trace frontend mistakes?
There is no evidence that the backend explicitly logs the received HTTP method when a 405 error occurs. The 405 Method Not Allowed response is automatically generated by Next.js when a request uses an HTTP method that isn't implemented in the route file. There's no custom error handling or logging for this specific situation in any of the examined route files.

If you need to trace frontend mistakes resulting in 405 errors, you would need to rely on Vercel's general request logs, which include the HTTP method, but there's no application-specific logging that would make these errors particularly easy to trace.

### Q5: What exact JSON error payload is returned when credits are exhausted?
The exact JSON error payload returned when credits are exhausted (for `/api/v1/ria/search`) is:

```json
{
  "error": "Free query limit reached. Create an account for more searches.",
  "code": "PAYMENT_REQUIRED",
  "remaining": 0,
  "isSubscriber": false,
  "upgradeRequired": true
}
```

This is returned with a 402 Payment Required HTTP status code. For authenticated but non-subscribed users, the message is slightly different: "Free query limit reached. Upgrade to continue."

### Q6: Is there a health check or test endpoint we can hit to confirm SSE is live and not disabled?
There is a general health check endpoint at `/api/debug/health` that checks various aspects of the system, including database connectivity and OpenAI availability. However, it doesn't specifically test SSE functionality. The health check endpoint returns:

```json
{
  "ok": true,
  "results": {
    "env": {
      "ok": true,
      "meta": {
        "aiProvider": "google",
        "openaiKeyPresent": true,
        "supabaseUrlPresent": true,
        "serviceRolePresent": true,
        "nodeEnv": "production"
      }
    },
    "supabase_ping": {
      "ok": true,
      "database_url": "https://llusjnpltqxhokycwzry.supabase.co...",
      "total_profiles": 41303,
      "placeholder_profiles": 0,
      "edward_jones_test": {
        "found": true,
        "legal_name": "EDWARD D. JONES & CO., L.P."
      }
    },
    "compute_vc_activity": {
      "ok": true,
      "meta": {
        "returnedRows": 1
      }
    },
    "openai": {
      "ok": true,
      "meta": {
        "model": "gpt-4o-mini-2024-07-18"
      }
    }
  }
}
```

This endpoint requires a security key in the request headers (`x-debug-key`) or query parameters (`?key=...`) matching the `DEBUG_HEALTH_KEY` environment variable.

There is no specific test endpoint for SSE functionality. To test if SSE is working, you would need to make an actual request to `/api/ask-stream` and verify that it returns a proper SSE stream.

### Q7: Are there any runtime limits in prod (Vercel Edge function timeout, memory, payload size) that could break long streams?
Yes, there are several Vercel serverless function runtime limits that could potentially affect long streams:

1. **Execution Timeout**: Vercel serverless functions have a maximum execution time of 60 seconds (for Pro and Enterprise plans). For hobby plans, the limit is 10 seconds. Long-running streams could hit this limit.

2. **Memory Limit**: Vercel serverless functions are limited to 1024MB (1GB) of memory. Memory leaks or inefficient processing of large datasets could hit this limit.

3. **Response Size Limit**: Vercel serverless functions have a maximum response size of 4.5MB. Very long streamed responses might exceed this limit.

4. **Streaming Duration**: Even with streaming responses, the underlying function still has the same execution time limit. The server must complete its work within the timeout period, even if it's streaming the response.

5. **Cold Starts**: Serverless functions that haven't been invoked recently may experience "cold starts" with higher latency. This doesn't break streams but can cause initial delays.

These limits could potentially break long-running streams, particularly if the request processing time exceeds the execution timeout or if the total response size exceeds 4.5MB.

### Q8: Does backend emit any telemetry (metrics, events) on credit decrement or stream start/end?
There is no evidence of explicit telemetry, metrics, or events being emitted for credit decrements or stream lifecycle events. The code shows basic console logging for errors:

```javascript
console.error('Error in /api/ask-stream:', error)
```

But there's no structured telemetry system or integration with monitoring platforms that would specifically track credit usage or streaming events. Credit decrements are recorded in the database (in the `user_queries` table), which could be queried for analytics purposes, but there's no real-time event emission for monitoring or dashboarding.

### Q9: On Stripe subscription upgrade/downgrade, how fast does subscription status propagate to `/api/subscription-status`?
Subscription status changes propagate immediately to `/api/subscription-status` upon processing of the Stripe webhook. The `/api/stripe-webhook` handler immediately updates the database when it receives subscription events:

```javascript
await supabaseAdmin.from('subscriptions').update({
  status: updatedSub.status,
  current_period_end: new Date(updatedSub.current_period_end * 1000).toISOString(),
  updated_at: new Date().toISOString(),
}).eq('user_id', userId);
```

The `/api/subscription-status` endpoint reads directly from the database on each request:

```javascript
const { data: subscription, error } = await supabaseAdmin
  .from('subscriptions')
  .select('*')
  .eq('user_id', userId)
  .single();
```

There's no caching layer between the database and the API, so as soon as the webhook updates the database, the next call to `/api/subscription-status` will reflect the new status. The only delay would be the time it takes for Stripe to send the webhook event after the subscription change (typically seconds, but can occasionally take longer).

### Q10: Are there any feature flags/env vars in prod that could silently suppress freebie logic?
There are no explicit feature flags or environment variables specifically designed to suppress or modify the freebie logic. The freebie counts are hardcoded in the route handlers:

- In `/api/subscription-status`: `const allowedQueries = 2 + Math.min(shareCount, 1);`
- In `/api/v1/ria/search`: The anonymous limit is checked with `if (anonCount >= 2)`

However, there are a few environment variables that could indirectly affect the authentication and credit systems:

1. `DEBUG_HEALTH_KEY`: Controls access to debug endpoints but doesn't affect freebies
2. `STRIPE_SECRET_KEY` and related vars: If misconfigured, could affect subscription validation
3. `SUPABASE_SERVICE_ROLE_KEY`: Required for database operations including credit tracking

None of these would "silently suppress" freebie logic specifically; they would more likely cause broader authentication or database access issues that would be more noticeable. There is no evidence of a dedicated feature flag system or specific environment variables designed to toggle or modify the freebie behavior.
